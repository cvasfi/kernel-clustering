{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapir/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(data,shrink=16):\n",
    "    shape=data.shape\n",
    "    result=np.zeros(shape)\n",
    "    nclusters=shape[0]/shrink\n",
    "    q_indices=np.zeros((shape[0],shape[1]))\n",
    "    #q_indices_onehot=mx.nd.zeros((shape[0],shape[1]*nclusters))\n",
    "    cluster_centers=np.zeros((nclusters, shape[1], shape[2], shape[3]))\n",
    "    \n",
    "    for channel in range(shape[1]):\n",
    "        c_data=data[:,channel,:,:]\n",
    "        cshape=c_data.shape\n",
    "        c_data_shaped=c_data.reshape((cshape[0], cshape[1]*cshape[2]))\n",
    "        \n",
    "        estimator = KMeans(n_clusters=nclusters)\n",
    "        estimator.fit(c_data_shaped.asnumpy())\n",
    "        \n",
    "        indices = estimator.predict(X=c_data_shaped.asnumpy())\n",
    "        data_quantized = np.array([estimator.cluster_centers_[idx] for idx in indices])\n",
    "\n",
    "        cluster_centers[:,channel,:,:] = estimator.cluster_centers_.reshape(nclusters,cshape[1],cshape[2])\n",
    "        q_indices[:,channel]=indices\n",
    "        \n",
    "        result[:,channel,:,:]=data_quantized.reshape(cshape)\n",
    "    \n",
    "    return result, cluster_centers, q_indices\n",
    "\n",
    "def get_onehot(data,nclusters, batch_size):\n",
    "    index_mat= mx.nd.one_hot(mx.nd.array(data),depth=nclusters).reshape(0,-1)\n",
    "    return  mx.nd.broadcast_axes(mx.nd.expand_dims(index_mat,axis=0),axis=0, size=batch_size)\n",
    "\n",
    "def convolve_codebook_lighter(data, filters, indices, fshape, output_shape):\n",
    "\n",
    "    #fshape  = codebookshape #4,16,3,3\n",
    "    #print filters.shape\n",
    "    #print fshape[0]*fshape[1]\n",
    "    #filters = mx.sym.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) #TODO: transpose is unnecessary!!\n",
    "    res = mx.nd.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1],\n",
    "                            no_bias=True, kernel=(3,3))\n",
    "    res = res.reshape((0,0,-1)) #flatten the image for matmul lookup\n",
    "    \n",
    "    res = mx.nd.batch_dot(lhs=indices,rhs=res)\n",
    "    \n",
    "    res = res.reshape((0,0,output_shape[2],output_shape[3]))\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_codebook_lighter_lookup(data, filters, indices, fshape, output_shape, outputholder):\n",
    "    #print outputholder.shape\n",
    "    #fshape  = codebookshape #4,16,3,3\n",
    "    #print filters.shape\n",
    "    #print fshape[0]*fshape[1]\n",
    "    #filters = mx.sym.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) #TODO: transpose is unnecessary!!\n",
    "    res = mx.nd.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1],\n",
    "                            no_bias=True, kernel=(3,3))\n",
    "    #res = res.reshape((0,0,-1)) #flatten the image for matmul lookup\n",
    "    \n",
    "    for iidx in range(res.shape[0]):\n",
    "        #am1=mx.nd.take(res[iidx], indices=indices)\n",
    "        #print am1.shape\n",
    "        outputholder[0]=mx.nd.sum(mx.nd.take(res[iidx], indices=indices), axis=1)\n",
    "        \n",
    "    #res = outputholder.reshape((0,0,output_shape[2],output_shape[3]))\n",
    "\n",
    "    return outputholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_indices(indices,n_cluster):\n",
    "    shape=indices.shape\n",
    "    res=mx.nd.zeros(shape)\n",
    "    for ch in range(shape[0]):\n",
    "        for idc in range(shape[1]):\n",
    "            res[ch,idc] = indices[ch,idc]+ idc*n_cluster\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "shrink = 8\n",
    "img=mx.nd.random.uniform(0, 1, shape=(1,16,32,32))\n",
    "fshape=(32,16,3,3)\n",
    "nclusters=fshape[0]/shrink\n",
    "orig_filter=mx.nd.random.uniform(0, 1, shape=fshape)\n",
    "\n",
    "\n",
    "qfilter, codebook_filter, indices = quantize(orig_filter, shrink=shrink)\n",
    "indices = mx.nd.array(indices)\n",
    "qfilter = mx.nd.array(qfilter)\n",
    "onehot_indices = get_onehot(indices,indices.shape[0]/shrink, batch_size=batch_size)\n",
    "flat_codebook_filter=  mx.nd.transpose(mx.nd.array(codebook_filter), axes=(1,0,2,3)).reshape((-1,1,0, 0))\n",
    "\n",
    "codebookshape=codebook_filter.shape\n",
    "indices_shape=indices.shape\n",
    "data_iter = mx.io.NDArrayIter(img, batch_size= batch_size)\n",
    "\n",
    "outputholder = mx.nd.zeros(((batch_size,fshape[0],30,30)))\n",
    "mod_ind=modify_indices(indices,nclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin =  time.time()\n",
    "\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='original1.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True)\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "for i in range(1000):\n",
    "    result_original = mx.nd.Convolution(data=img,weight=qfilter, num_filter=fshape[0], kernel=(3,3), no_bias=True).asnumpy()\n",
    "\n",
    "mx.profiler.set_state('stop')\n",
    "\n",
    "print time.time() - begin\n",
    "print mx.profiler.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin =  time.time()\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='clustered1.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True,\n",
    "                      profile_symbolic=True)\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "for i in range(1000):\n",
    "    result_clustered = convolve_codebook_lighter(data=img, filters = flat_codebook_filter, indices=onehot_indices, fshape = codebookshape,\n",
    "                               output_shape=(batch_size,fshape[0],30,30)).asnumpy()\n",
    "    \n",
    "mx.profiler.set_state('stop')\n",
    "\n",
    "print time.time() - begin\n",
    "print mx.profiler.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(np.square(result_clustered - result_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.18899106979\n",
      "\n",
      "Profile Statistics.\n",
      "\tNote that counter items are counter values and not time units.\n",
      "Device Storage\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "Memory: cpu/0                        8113        2075.6321           0.0160        4264.4321        2132.2080\n",
      "\n",
      "MXNET_C_API\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "MXNDArrayGetContext                  1024           0.4750           0.0000           0.0010           0.0005\n",
      "MXNDArrayGetStorageType                 1           0.0010           0.0010           0.0010           0.0010\n",
      "MXNDArrayGetDType                    2060           0.9370           0.0000           0.0080           0.0005\n",
      "MXNDArrayAt                          2000           5.0630           0.0010           0.1430           0.0025\n",
      "MXNet C API Calls                   27994          27.9940           0.0010          27.9940          13.9965\n",
      "MXNet C API Concurrency             55988           0.0000           0.0000           0.0010           0.0005\n",
      "MXImperativeInvokeEx                 5561         176.7100           0.0090           4.3760           0.0318\n",
      "MXNDArrayGetShape                    8142           5.2300           0.0000           0.2120           0.0006\n",
      "MXNDArrayReshape64                   1058           2.0630           0.0010           0.0080           0.0019\n",
      "MXNDArrayFree                        7109           8.4810           0.0000           0.1280           0.0012\n",
      "MXNDArraySyncCopyToCPU               1032        8584.2490           0.0020          16.9620           8.3181\n",
      "MXNDArrayCreateEx                       4           0.0180           0.0030           0.0060           0.0045\n",
      "MXNDArraySyncCopyFromCPU                3           1.4330           0.0260           1.3770           0.4777\n",
      "\n",
      "operator\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "sum                                  2000       12776.1719           5.2910          13.6490           6.3881\n",
      "Convolution                          2000         808.2140           0.2780           1.3400           0.4041\n",
      "_plus_scalar                         1024           6.0810           0.0010           0.3900           0.0059\n",
      "_random_uniform                         4           5.0320           0.0580           2.4590           1.2580\n",
      "take                                 2000        4093.1841           1.6620           5.5130           2.0466\n",
      "broadcast_axis                          2           0.0420           0.0200           0.0220           0.0210\n",
      "_slice_assign                        1024          17.2200           0.0020           3.6410           0.0168\n",
      "slice                                1056          35.7070           0.0030           4.0910           0.0338\n",
      "WaitForVar                           2014         102.8610           0.0020           1.1540           0.0511\n",
      "CopyCPU2CPU                          2002          35.8280           0.0050           0.2070           0.0179\n",
      "one_hot                                 2           3.6590           1.8280           1.8310           1.8295\n",
      "DeleteVariable                       8102          26.2400           0.0010           0.1280           0.0032\n",
      "transpose                               2           0.0220           0.0110           0.0110           0.0110\n",
      "expand_dims                             2           0.0290           0.0140           0.0150           0.0145\n",
      "_zeros                                  4           0.1190           0.0060           0.0540           0.0298\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "begin =  time.time()\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='clustered1.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True,\n",
    "                      profile_symbolic=True)\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    result_clustered_2 = convolve_codebook_lighter_lookup(data=img, filters = flat_codebook_filter, \n",
    "                               indices=mod_ind,fshape = codebookshape,\n",
    "                               output_shape=(batch_size,fshape[0],30,30), outputholder=outputholder).asnumpy()\n",
    "    \n",
    "mx.profiler.set_state('stop')\n",
    "    \n",
    "print time.time() - begin\n",
    "print mx.profiler.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(np.square(result_clustered_2 - result_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print indices.asnumpy()[1]\n",
    "print modify_indices(indices, nclusters).asnumpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='clustered1.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True,\n",
    "                      profile_symbolic=True)\n",
    "mx.profiler.set_state('run')\n",
    "mx.profiler.set_state('stop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin =  time.time()\n",
    "\n",
    "for i in range(1000):\n",
    "    result_clustered = convolve_codebook_lighter_sparse(data=img, filters = flat_codebook_filter, indices=onehot_indices, fshape = codebookshape,\n",
    "                               output_shape=(batch_size,fshape[0],30,30), outputholder=outputholder).asnumpy()\n",
    "print time.time() - begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_codebook_lighter_sparse(data, filters, indices, fshape, output_shape, outputholder):\n",
    "\n",
    "    #fshape  = codebookshape #4,16,3,3\n",
    "    #print filters.shape\n",
    "    #print fshape[0]*fshape[1]\n",
    "    #filters = mx.sym.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) #TODO: transpose is unnecessary!!\n",
    "    res = mx.nd.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1],\n",
    "                            no_bias=True, kernel=(3,3))\n",
    "    res = res.reshape((0,0,-1)) #flatten the image for matmul lookup\n",
    "    \n",
    "    for iidx in range(res.shape[0]):\n",
    "        outputholder[0]=mx.nd.sparse.dot(indices[0],res[iidx])\n",
    "    \n",
    "    res = outputholder.reshape((0,0,output_shape[2],output_shape[3]))\n",
    "\n",
    "    return res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
