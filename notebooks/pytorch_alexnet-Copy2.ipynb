{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lookupconv(nn.Conv2d):\n",
    "    def __init__(self, indices, *args, **kwargs):\n",
    "        super(lookupconv, self).__init__(*args, **kwargs)\n",
    "        self.indices=indices\n",
    "        print \"init time\"\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x =super(lookupconv, self).forward(input)\n",
    "        return torch.index_select(x, 1, self.indices)\n",
    "        \n",
    "class lookupfc(nn.Linear):\n",
    "    def __init__(self, indices, *args, **kwargs):\n",
    "        super(lookupfc, self).__init__(*args, **kwargs)\n",
    "        self.indices=indices\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x =super(lookupfc, self).forward(input)\n",
    "        return torch.index_select(x, 1, self.indices)\n",
    "    \n",
    "    \n",
    "class AlexNet_lookup(nn.Module):\n",
    "\n",
    "    def __init__(self, ochannels, indices, dummyfcidx, num_classes=1000):\n",
    "        super(AlexNet_lookup, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            lookupconv(indices[0], 3, ochannels[0], kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            lookupconv(indices[1], 96, ochannels[1], kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            lookupconv(indices[2], 256, ochannels[2], kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            lookupconv(indices[3], 384, ochannels[3], kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            lookupconv(indices[4], 384, ochannels[4], kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init time\n",
      "init time\n",
      "init time\n",
      "init time\n",
      "init time\n"
     ]
    }
   ],
   "source": [
    "def get_with_context(data,ctx=False):\n",
    "    if ctx:\n",
    "        return data.cuda()\n",
    "    return data\n",
    "\n",
    "def get_res_with_ctx(inp,ctx=False):\n",
    "    if ctx:\n",
    "        return inp.cpu().data.numpy()\n",
    "    else:\n",
    "        return inp.data.numpy()\n",
    "    \n",
    "    \n",
    "usecuda = False\n",
    "shrink=4\n",
    "ochannels = [96,256,384,384,256]\n",
    "fcnums = []\n",
    "indices=[]\n",
    "onehot_indices=[]\n",
    "compressed_ochannels=[]\n",
    "\n",
    "fc_dummy_index= get_with_context(torch.LongTensor(np.random.choice(4096/shrink, 4096)))\n",
    "\n",
    "for och in ochannels:\n",
    "    indices.append(get_with_context(torch.LongTensor(np.random.choice(och/shrink, och)), usecuda))\n",
    "    onehot_indices.append(get_with_context(torch.rand(och, och/shrink),usecuda))\n",
    "    compressed_ochannels.append(och/shrink)\n",
    "    \n",
    "x=get_with_context(torch.rand(128,3,224,224),usecuda)\n",
    "\n",
    "alexnet        = get_with_context(AlexNet(),usecuda)\n",
    "alexnet_lookup = get_with_context(AlexNet_lookup(compressed_ochannels, indices, fc_dummy_index),usecuda)\n",
    "#alexnet_dot    = get_with_context(AlexNet_dot(compressed_ochannels, onehot_indices, fc_dummy_index),usecuda)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709.412333965\n",
      "300.882972956\n"
     ]
    }
   ],
   "source": [
    "begin=time.time()\n",
    "for i in range(100):\n",
    "    res1=get_res_with_ctx(alexnet(x), usecuda)\n",
    "    time1=\n",
    "print time.time()-begin\n",
    "\n",
    "begin=time.time()\n",
    "for i in range(100):\n",
    "    res2=get_res_with_ctx(alexnet_lookup(x), usecuda)\n",
    "print time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "for i in range(5000):\n",
    "    res3=get_res_with_ctx(alexnet_dot(x), usecuda)\n",
    "print time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128, 30, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrink=2\n",
    "dummy=torch.rand(7,16,32,32)\n",
    "dummyfilter=torch.rand(128,16,3,3)\n",
    "dummyfilter2=torch.rand(16*128/shrink,1,3,3)\n",
    "indices=torch.Tensor(np.random.choice(128/2,128)).reshape(-1)\n",
    "\n",
    "c1=F.conv2d(dummy,dummyfilter)\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1024, 30, 30])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_1=F.conv2d(dummy,dummyfilter2,groups=16)\n",
    "print c2_1.shape\n",
    "c2_2=torch.index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            lookupfc(dummyfcidx, 256 * 6 * 6, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            lookupfc(dummyfcidx, 4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet_lookup(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "        relu1 = nn.ReLU(inplace=True),\n",
    "        pool1 = nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "        relu2 = nn.ReLU(inplace=True),\n",
    "        pool2 = nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "        relu3 = nn.ReLU(inplace=True),\n",
    "        conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "        relu4 = nn.ReLU(inplace=True),\n",
    "        conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        relu5 = nn.ReLU(inplace=True),\n",
    "        pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        \n",
    "        drop1 = nn.Dropout(),\n",
    "        fc1 = nn.Linear(256 * 6 * 6, 4096),\n",
    "        relu6 = nn.ReLU(inplace=True),\n",
    "        drop2 = nn.Dropout(),\n",
    "        fc2 = nn.Linear(4096, 4096),\n",
    "        relu7 = nn.ReLU(inplace=True),\n",
    "        fc3 = nn.Linear(4096, num_classes),\n",
    "        \n",
    "    \n",
    "    def lookupconv(self,in_data, in_function, indices):\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
