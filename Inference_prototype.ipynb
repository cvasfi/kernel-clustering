{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapir/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_codebook_ndarray(data, codebook):\n",
    "    filters = codebook\n",
    "    fshape  = filters.shape\n",
    "    \n",
    "    filters = mx.nd.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) \n",
    "    res = mx.nd.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1], no_bias=True, kernel=(3,3))\n",
    "    res = res.expand_dims(1)\n",
    "    res = res.reshape((0,fshape[1],fshape[0], 0, 0))\n",
    "    res = mx.nd.transpose(res,axes=(0,2,1,3,4))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(data,shrink=8):\n",
    "    shape=data.shape\n",
    "    result=np.zeros(shape)\n",
    "    nclusters=shape[0]/shrink\n",
    "    q_indices=np.zeros((shape[0],shape[1]))\n",
    "    cluster_centers=np.zeros((nclusters, shape[1], shape[2], shape[3]))\n",
    "    \n",
    "    for channel in range(shape[1]):\n",
    "        c_data=data[:,channel,:,:]\n",
    "        cshape=c_data.shape\n",
    "        c_data_shaped=c_data.reshape((cshape[0], cshape[1]*cshape[2]))\n",
    "        \n",
    "        estimator = KMeans(n_clusters=nclusters)\n",
    "        estimator.fit(c_data_shaped.asnumpy())\n",
    "        \n",
    "        indices = estimator.predict(X=c_data_shaped.asnumpy())\n",
    "        data_quantized = np.array([estimator.cluster_centers_[idx] for idx in indices])\n",
    "\n",
    "        cluster_centers[:,channel,:,:] = estimator.cluster_centers_.reshape(nclusters,cshape[1],cshape[2])\n",
    "        q_indices[:,channel]=indices\n",
    "        \n",
    "        result[:,channel,:,:]=data_quantized.reshape(cshape)\n",
    "    \n",
    "    return result, cluster_centers, q_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_codebook(data, indices, codebookshape, output_shape):\n",
    "    filters = mx.sym.Variable(\"codebook\", shape=codebookshape)\n",
    "    fshape  = codebookshape #4,16,3,3\n",
    "    index_shape=indices.shape\n",
    "    \n",
    "    filters = mx.sym.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) #TODO: transpose is unnecessary!!\n",
    "    res = mx.sym.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1], no_bias=True, kernel=(3,3))\n",
    "    res = res.expand_dims(1)\n",
    "    res = res.reshape((0,fshape[1],fshape[0], 0, 0))\n",
    "    res = mx.sym.transpose(res,axes=(0,2,1,3,4)) #lookup table\n",
    "    \n",
    "    #hacky because multi-dim indexing isn't allowed\n",
    "    res = mx.sym.reshape(data=res,shape=(-1,0),reverse=1) #(sample*nclusters*channel*W,H)\n",
    "    #now looking up the results\n",
    "    \n",
    "    #print res[0,1,0] #7, 4, 16 ,30, 30\n",
    "    print index_shape#7,4,16,30,30\n",
    "    lres=[]\n",
    "    #TODO: find a way to implement with less loops\n",
    "    for sample in range(output_shape[0]):\n",
    "        filterwise_list=[]\n",
    "        for fltr in range(index_shape[0]):\n",
    "            channelwise_list=[]\n",
    "            for ch in range(index_shape[1]):\n",
    "                            ## (((sample*4+cluster)*channels)*channel)*width\n",
    "                slice_begin = (((sample*fshape[0]+indices[fltr,ch])*fshape[1]+ch)*output_shape[2],0)\n",
    "                slice_end   = (slice_begin[0]+output_shape[2],output_shape[3])\n",
    "\n",
    "                #channelwise_list.append(res[sample][indices[fltr,ch]][ch][0])\n",
    "                channelwise_list.append(mx.sym.slice(data=res, begin=slice_begin, end=slice_end))\n",
    "                \n",
    "            filterwise_list.append(mx.sym.sum(mx.sym.stack(*channelwise_list),axis=0))\n",
    "        lres.append(mx.sym.stack(*filterwise_list))\n",
    "    lres=mx.sym.stack(*lres)                 \n",
    "                \n",
    "    \n",
    "    \n",
    "    return lres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mx.nd.random.uniform(0, 1, shape=(8,64,32,32))\n",
    "labels=mx.nd.array([1,0,1,0,0,1,0,1])\n",
    "fshape=(128,64,3,3)\n",
    "orig_filter=mx.nd.random.uniform(0, 1, shape=fshape)\n",
    "\n",
    "qfilter, codebook_filter, indices = quantize(orig_filter)\n",
    "indices=indices.astype(int)\n",
    "codebookshape=codebook_filter.shape\n",
    "indices_shape=indices.shape\n",
    "data_iter = mx.io.NDArrayIter(img, batch_size= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"codebook\": mx.nd.array(codebook_filter)}\n",
    "data=mx.sym.Variable(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sym=convolve_codebook(data=data,indices= indices,codebookshape= codebookshape, output_shape=(4,128,30,30))\n",
    "mod=mx.mod.Module(symbol=sym, context=mx.gpu())\n",
    "#mod.init_params(arg_params=args)\n",
    "mod.bind(for_training=False, data_shapes=data_iter.provide_data)#,{'codebook': mx.nd.array(codebook_filter)}], label_shapes=None)\n",
    "mod.set_params(args,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='clustered_profile.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True,\n",
    "                      profile_symbolic=True)\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "result=mod.predict(eval_data=data_iter).asnumpy()\n",
    "\n",
    "mx.profiler.set_state('stop')\n",
    "print(mx.profiler.dumps())\n",
    "\n",
    "#print time.time()-begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "result=mod.predict(eval_data=data_iter).asnumpy()\n",
    "print time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##baseline\n",
    "args2={\"filters\":mx.nd.array(qfilter)}\n",
    "\n",
    "baseline_filters=mx.sym.Variable(\"filters\")\n",
    "sym2=mx.sym.Convolution(data=data,weight=baseline_filters, num_filter=128, kernel=(3,3), no_bias=True)\n",
    "\n",
    "mod2=mx.mod.Module(symbol=sym2, context=mx.gpu())\n",
    "#mod.init_params(arg_params=args)\n",
    "mod2.bind(for_training=False, data_shapes=data_iter.provide_data)#,{'codebook': mx.nd.array(codebook_filter)}], label_shapes=None)\n",
    "mod2.set_params(args2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='baseline_profile.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True)\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "result2=mod2.predict(eval_data=data_iter).asnumpy()\n",
    "\n",
    "mx.profiler.set_state('stop')\n",
    "print(mx.profiler.dumps())\n",
    "print time.time()-begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.square(result-result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapir/miniconda2/lib/python2.7/site-packages/mxnet/module/base_module.py:54: UserWarning: \u001b[91mYou created Module with Module(..., label_names=['softmax_label']) but input with name 'softmax_label' is not found in symbol.list_arguments(). Did you mean one of:\n",
      "\tdata\n",
      "\tfilters\u001b[0m\n",
      "  warnings.warn(msg)\n",
      "/home/tapir/miniconda2/lib/python2.7/site-packages/mxnet/module/base_module.py:66: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##baseline2\n",
    "reshaped_filter = mx.nd.transpose(mx.nd.array(codebook_filter), axes=(1,0,2,3)).reshape((-1,1,0, 0))\n",
    "args3={\"filters\":reshaped_filter}\n",
    "\n",
    "baseline3_filters=mx.sym.Variable(\"filters\")\n",
    "sym3= mx.sym.Convolution(data=data, weight=baseline3_filters, num_group=codebookshape[1], \n",
    "                         num_filter=codebookshape[0]*codebookshape[1], no_bias=True, kernel=(3,3))\n",
    "\n",
    "\n",
    "mod3=mx.mod.Module(symbol=sym3, context=mx.gpu())\n",
    "#mod.init_params(arg_params=args)\n",
    "mod3.bind(for_training=False, data_shapes=data_iter.provide_data)#,{'codebook': mx.nd.array(codebook_filter)}], label_shapes=None)\n",
    "mod3.set_params(args3, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0629680156708\n",
      "\n",
      "Profile Statistics.\n",
      "\tNote that counter items are counter values and not time units.\n",
      "Device Storage\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "Memory: gpu/0                           8       14751.0117       14751.0117       58987.8125       22118.4004\n",
      "\n",
      "MXNET_C_API\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "MXNDArraySyncCopyToCPU                  1          60.1530          60.1530          60.1530          60.1530\n",
      "MXNDArrayGetDType                       5           0.0030           0.0000           0.0010           0.0006\n",
      "MXNet C API Calls                      70           0.0700           0.0010           0.0700           0.0345\n",
      "MXNet C API Concurrency               140           0.0000           0.0000           0.0010           0.0005\n",
      "MXNDArrayGetShape                      35           0.0240           0.0000           0.0010           0.0007\n",
      "MXImperativeInvokeEx                    6           0.1390           0.0160           0.0420           0.0232\n",
      "MXNDArraySlice                          6           0.0100           0.0010           0.0030           0.0017\n",
      "MXNDArrayFree                           9           0.0300           0.0000           0.0250           0.0033\n",
      "MXExecutorForward                       2           0.0070           0.0030           0.0040           0.0035\n",
      "MXNDArrayGetContext                     3           0.0010           0.0000           0.0010           0.0003\n",
      "MXNDArrayCreateEx                       3           0.8280           0.0030           0.8220           0.2760\n",
      "\n",
      "operator\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "SyncCopyGPU2CPU                         2          38.0310          19.0130          19.0180          19.0155\n",
      "DeleteVariable                          6           0.0340           0.0050           0.0070           0.0057\n",
      "CopyGPU2GPU                             8          20.7480           2.2380           3.2620           2.5935\n",
      "CopyCPU2GPU                             4           4.9530           0.9470           1.5290           1.2383\n",
      "[Convolution]                           4          63.4950           4.7320          27.0140          15.8737\n",
      "WaitForVar                              2           0.0520           0.0070           0.0450           0.0260\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mx.profiler.set_config(profile_all=True,\n",
    "                        filename='baseline_profile.json',  # File used for chrome://tracing visualization\n",
    "                        continuous_dump=True,\n",
    "                        aggregate_stats=True)\n",
    "mx.profiler.set_state('run')\n",
    "begin=time.time()\n",
    "\n",
    "result3=mod3.predict(eval_data=data_iter).asnumpy()\n",
    "print time.time()-begin\n",
    "\n",
    "mx.profiler.set_state('stop')\n",
    "print(mx.profiler.dumps())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=convolve_codebook_ndarray(img,args[\"codebook\"])\n",
    "np.array_equal(result.asnumpy(),result2.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=mx.nd.zeros((7,4,16,30,30))\n",
    "\n",
    "for s in range(7):\n",
    "    for i in range(4):\n",
    "        filled= np.empty((16,30,30))\n",
    "        filled.fill(i+s)\n",
    "        aa[s,i,:,:,:] = mx.nd.array(filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_idx=mx.nd.array(np.random.choice(4,(32,16)))\n",
    "print lookup_idx[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lres=mx.nd.tile(data=mx.nd.zeros_like(aa[0,0,0,:,:]),reps=(7,32,1,1))\n",
    "lres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lres=mx.nd.zeros((7,32,30,30))\n",
    "\n",
    "for sample in range(7):#7\n",
    "    for fltr in range(lookup_idx.shape[0]):#32 \n",
    "        for ch in range(lookup_idx.shape[1]):#16\n",
    "            lres[sample,fltr]+=aa[sample,lookup_idx[fltr,ch],ch,:,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how you slice ------------------------------------\n",
    "print aa[1,3,15,0]\n",
    "print aa.shape\n",
    "samp=1\n",
    "cls=3\n",
    "ch=15\n",
    "print ((samp*4+cls)*16+ch)*30\n",
    "aa2=mx.nd.reshape(data=aa,shape=(-1,0),reverse=1)\n",
    "print mx.nd.slice(data=aa2, begin=(((samp*4+cls)*16+ch)*30,0), end=(((samp*4+cls)*16+ch)*30+30,30))\n",
    "#print aa2[480*7:480*7+30]\n",
    "#print mx.nd.slice_axis(data=aa,axis=2,begin=0,end=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lres2=[]\n",
    "for sample in range(7):#7\n",
    "    filterwise_list=[]\n",
    "    for fltr in range(lookup_idx.shape[0]):#32 \n",
    "        channelwise_list=[]\n",
    "        for ch in range(lookup_idx.shape[1]):#16\n",
    "            \n",
    "            channelwise_list.append(aa[sample,lookup_idx[fltr,ch],ch,:,:][0])\n",
    "        filterwise_list.append(mx.nd.sum(mx.nd.stack(*channelwise_list),axis=0))\n",
    "    lres2.append(mx.nd.stack(*filterwise_list))\n",
    "lres2=mx.nd.stack(*lres2)\n",
    "print lres2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=mx.nd.stack(c,b, axis = 1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.nd.tile(data=a,reps=(7,16,1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.nd.sum(lookup_idx[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lres2[0][6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mx.nd.random.uniform(0, 1, shape=(8,16,32,32))\n",
    "data_iter = mx.io.NDArrayIter(img, batch_size= 3, label_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.provide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.provide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tensors(data, l_indices, index_shape, batch_size):\n",
    "    lookup_idx = mx.sym.Variable(\"indices\", shape=indes_shape)\n",
    "  \n",
    "    lres=mx.nd.tile(data=mx.nd.zeros_like(data[0,0,0,:,:]),reps=(7,32,1,1))\n",
    "    \n",
    "    for sample in range(batch_size):\n",
    "        for fltr in range(indes_shape[0]):\n",
    "            for ch in range(index_shape[1]):\n",
    "                lres[sample,fltr]+=aa[sample,lookup_idx[fltr,ch],ch,:,:][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_codebook_nd(data, indices, codebook, codebookshape, output_shape):\n",
    "    #filters = mx.sym.Variable(\"codebook\", shape=codebookshape)\n",
    "    filters=codebook\n",
    "    \n",
    "    fshape  = codebookshape #4,16,3,3\n",
    "    index_shape=indices.shape\n",
    "    \n",
    "    filters = mx.nd.transpose(filters, axes=(1,0,2,3)).reshape((-1,1,0, 0)) #TODO: transpose is unnecessary!!\n",
    "    res = mx.nd.Convolution(data=data, weight=filters, num_group=fshape[1], num_filter=fshape[0]*fshape[1], no_bias=True, kernel=(3,3))\n",
    "    res = res.expand_dims(1)\n",
    "    res = res.reshape((0,fshape[1],fshape[0], 0, 0))\n",
    "    res = mx.nd.transpose(res,axes=(0,2,1,3,4)) #lookup table\n",
    "    \n",
    "    #hacky because multi-dim indexing isn't allowed\n",
    "    res = mx.nd.reshape(data=res,shape=(-1,0),reverse=1) #(sample*nclusters*channel*W,H)\n",
    "    #now looking up the results\n",
    "    \n",
    "    #print res[0,1,0] #7, 4, 16 ,30, 30\n",
    "    #print index_shape#7,4,16,30,30\n",
    "    lres=[]\n",
    "    #TODO: find a way to implement with less loops\n",
    "    for sample in range(output_shape[0]):\n",
    "        filterwise_list=[]\n",
    "        for fltr in range(index_shape[0]):\n",
    "            channelwise_list=[]\n",
    "            for ch in range(index_shape[1]):\n",
    "                            ## (((sample*4+cluster)*channels)*channel)*width\n",
    "                slice_begin = (((sample*fshape[0]+indices[fltr,ch])*fshape[1]+ch)*output_shape[2],0)\n",
    "                slice_end   = (slice_begin[0]+output_shape[2],output_shape[3])\n",
    "                \n",
    "                #print slice_begin\n",
    "                #print slice_end\n",
    "                #channelwise_list.append(res[sample][indices[fltr,ch]][ch][0])\n",
    "                channelwise_list.append(mx.nd.slice(data=res, begin=slice_begin, end=slice_end))\n",
    "                \n",
    "            filterwise_list.append(mx.nd.sum(mx.nd.stack(*channelwise_list),axis=0))\n",
    "        lres.append(mx.nd.stack(*filterwise_list))\n",
    "    lres=mx.nd.stack(*lres)                 \n",
    "                \n",
    "    \n",
    "    \n",
    "    return lres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mx.nd.random.uniform(0, 1, shape=(10,64,32,32))\n",
    "fshape=(128,64,3,3)\n",
    "orig_filter=mx.nd.random.uniform(0, 1, shape=fshape)\n",
    "\n",
    "qfilter, codebook_filter, indices = quantize(orig_filter)\n",
    "indices=indices.astype(int)\n",
    "codebook_filter=mx.nd.array(codebook_filter)\n",
    "codebookshape=codebook_filter.shape\n",
    "indices_shape=indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "print\"=======================\"\n",
    "well = convolve_codebook_nd(data=img,codebook=codebook_filter,indices=indices,output_shape=(10,128,30,30), codebookshape=codebookshape)\n",
    "print  well.asnumpy().shape\n",
    "print time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=time.time()\n",
    "print \"=========================\"\n",
    "well2=mx.nd.Convolution(data=img,weight=mx.nd.array(qfilter),kernel=(3,3),num_filter=128, no_bias=True)\n",
    "print  well2.asnumpy().shape\n",
    "print time.time()-begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.nd.mean(well-well2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mx.nd.random.uniform(0, 1, shape=(8,16,32,32))\n",
    "labels=mx.nd.array([1,0,1,0,0,1,0,1])\n",
    "labels = mx.nd.one_hot(depth=2,indices=labels)\n",
    "fshape=(32,16,3,3)\n",
    "orig_filter=mx.nd.random.uniform(0, 1, shape=fshape)\n",
    "\n",
    "qfilter, codebook_filter, indices = quantize(orig_filter)\n",
    "indices=indices.astype(int)\n",
    "codebookshape=codebook_filter.shape\n",
    "indices_shape=indices.shape\n",
    "data_iter = mx.io.NDArrayIter(img, batch_size= 4, label=labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"codebook\": mx.nd.array(codebook_filter)}\n",
    "data=mx.sym.Variable(\"data\")\n",
    "sym=convolve_codebook(data=data,indices= indices,codebookshape= codebookshape, output_shape=(4,32,30,30))\n",
    "sym=mx.sym.Flatten(sym)\n",
    "sym = mx.symbol.FullyConnected(data=sym, num_hidden=2, no_bias=True)\n",
    "sym = mx.symbol.SoftmaxOutput(data=sym, name='softmax')\n",
    "\n",
    "mod=mx.mod.Module(symbol=sym, context=mx.cpu())\n",
    "#mod.init_params(arg_params=args)\n",
    "mod.bind( data_shapes=data_iter.provide_data, label_shapes=data_iter.provide_label)#,{'codebook': mx.nd.array(codebook_filter)}], label_shapes=None)\n",
    "mod.set_params(args,None,allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_params = {'learning_rate': 0.0000001,\n",
    "                       'momentum': 0.9,\n",
    "                       'wd': 0.0005,\n",
    "                       'clip_gradient': None,\n",
    "                       'rescale_grad': 1.0}\n",
    "\n",
    "mod.fit(data_iter, eval_data=data_iter, arg_params=args,eval_metric=['acc'],optimizer='sgd',num_epoch=10\n",
    "        ,optimizer_params=optimizer_params\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.predict(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newargs=mod.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newargs[0]['codebook'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
